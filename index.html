<!DOCTYPE html>
<html lang="en">
<head>

  <!-- Basic Page Needs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta charset="utf-8">
  <title>The Fourth Summer School on Statistical Methods for Linguistics and Psychology</title>
  <meta name="description" content="">
  <meta name="author" content="">

  <!-- Mobile Specific Metas
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- FONT
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link href="//fonts.googleapis.com/css?family=Raleway:400,300,600" rel="stylesheet" type="text/css">

  <!-- CSS
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href="css/normalize.css">
  <link rel="stylesheet" href="css/skeleton.css">

  <!-- Favicon
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="icon" type="image/png" href="images/lorikeet.jpg">

</head>
<body>

<section class="about">
  <div class="container">
    <h4>Welcome to the Fourth Summer School on Statistical Methods for Linguistics and Psychology, 7-11 September 2020</h4>

    <div class="row">
     </div>

    <br><br><br>
    <div>
    <h3>Application, dates, location</h3>
        <ul>
          <li>Dates: 7-11 September 2020.</li>
          <li>Times: The summer school is being taught completely online, the times will be decided closer to September.</li>
          <li>Location: The course will be taught virtually during this week, using pre-recorded videos, moodle, and Zoom for daily real-time meetings. <strong>For the Introductory courses, the recorded lectures  will be available for free online to everyone (we will decide about the other courses later; watch this space)</strong>.
</li>
          <li><strong>Application period: 15 Jan to 1 April 2020</strong>.  Applications are closed. We had approximately 320 applications this year.</li>
          </ul>
</div>

<div>
     <h3>Brief history of the summer school, and motivation</h3>

The SMLP summer school was started by Shravan Vasishth in 2017, as part of a <a href="https://www.uni-potsdam.de/en/sfb1287/projects/infrastructure-service-training-and-central-projects/project-q.html">methods project</a> funded within the <a href="https://www.uni-potsdam.de/sfb1287/index.html">SFB 1287</a>. The summer school aims to fill a gap in statistics education, specifically within the fields of linguistics and psychology. One goal of the summer school is to provide comprehensive training in the theory and application of statistics, with a special focus on the linear mixed model.  Another major goal is to make Bayesian data analysis a standard part of the toolkit for the linguistics and psychology researcher. Over time, the summer school has evolved to have at least four parallel streams: beginning and advanced courses in frequentist and Bayesian statistics. These may be expanded to more parallel sessions in future editions. We typically admit a total of 120 participants (in 2019, we had some 450 applications). In addition to the all-day courses, we regularly invite speakers to give lectures on important current issues relating to statistics. Previous editions of the summer school: <a href="https://vasishth.github.io/smlp2019/">2019</a>, <a href="https://vasishth.github.io/SMLP2018/">2018</a>, <a href="https://vasishth.github.io/SMLP2017/">2017</a>.
</div>


<div>
     <h3>Code of conduct</h3>

All participants will be expected to follow the (<a href="http://mc-stan.org/events/stancon2018/stancon-code_of_conduct.html">code of conduct</a>, taken from <a href="http://mc-stan.org/events/stancon2018/">StanCon 2018</a>. In case a participant has any concerns, please contact any of the following instructors: Audrey Bürki, Shravan Vasishth, Bruno Nicenboim, João Veríssimo, or Reinhold Kliegl. 

</div>

<div>
     <h3>Invited lecturers</h3>

Because the summer school had to be switched to online modality, two of the lecturers, Jonah Gabry, and Robert Grant, cannot teach this year.

        <ul>
          <li><a href="http://pages.stat.wisc.edu/~bates/">Douglas Bates</a> (co-instructor for Advanced methods in frequentist statistics with Julia)</li>
          <li><a href="https://phillipalday.com/">Phillip Alday</a> (Advanced methods in frequentist statistics with Julia)</li>
             </ul>
</div>


<div>
     <h3>Invited keynote speakers</h3>

        <ul>
        <li><strong>Wed 9 Sept</strong>:<a href="https://www.mpi.nl/people/bergmann-christina">Christina Bergmann</a> (Title: <strong>The "new" science: transparent, cumulative, and collaborative)</strong><br>

<strong>Abstract</strong>: 
        <i>Transparency, cumulative thinking, and a collaborative mindset are key ingredients for a more robust foundation for experimental studies and theorizing. 

Empirical sciences have long faced criticism for some of the statistical tools they use and the overall approach to experimentation; a debate that has in the last decade gained momentum in the context of the "replicability crisis." Culprits were quickly identified: False incentives led to "questionable research practices" such as HARKing and p-hacking and single, "exciting" results are over-emphasized. Many solutions are gaining importance, from open data, code, and materials - rewarded with badges - over preregistration to a shift away from focusing on
p values. There are a host of options to choose from; but how can we pick the right existing and emerging tools and techniques to improve transparency, aggregate evidence, and work together? I will discuss answers fitting my own work spanning empirical (including large-scale), computational, and meta-scientific studies, with a focus on strategies to see each study for what it is: A single brushstroke of a larger picture.</i>

        </li>
          <li><strong>Fri 11 Sept</strong>: <a href="http://pcl.missouri.edu/jeff/">Jeff Rouder</a> Title: <strong>Robust cognitive modeling</strong><br>

<strong>Abstract</strong>:

In the past decade, there has been increased emphasis on the replicability and robustness of effects in psychological science.  And more recently, the emphasis has been extended to cognitive process modeling of behavioral data under the rubric of “robust models."  Making analyses open and replicable is fairly straightforward; more difficult is understanding what robust models are and how to specify and analyze them.  Of particular concern is whether subjectivity is part of robust modeling, and if so, what can be done to guard against undue influence of subjective elements.  Indeed, it seems the concept of "researchers' degrees of freedom" plays writ large in modeling. 

I take the challenge of subjectivity in robust modeling head on.  I discuss what modeling does in science, how to specify models that capture theoretical positions, how to add value in analysis, and how to understand the role of subjective specification in drawing substantive inferences.  I will extend the notion of robustness to mixed designs and hierarchical models as these are common in real-world experimental settings.
</li>
        </ul>
</div>        

<div>
<h3>Curriculum and schedule</h3>

We offer foundational/introductory and advanced courses in Bayesian and frequentist statistics. When applying, participants are expected to choose only one stream.<br>

<strong>The schedule</strong> for each stream can be downloaded as a pdf file from <a href="https://vasishth.github.io/smlp2020/SMLP2020schedule.pdf">here</a>.


<ul>
<li><strong>Introduction to Bayesian regression modeling with brms</strong> (maximum 30 participants). Taught by <a href="https://vasishth.github.io/">Shravan Vasishth</a>, <a href="https://annlaurin.github.io/">Anna Laurinavichyute</a>, and <a href="https://paulalisson.github.io/">Paula Lisson</a></li>

(<i>This course is an introduction to Bayesian modeling.</i>)  Topics to be covered: Introduction to Bayesian data analysis, GLMs for Binary/Binomial Data, GLMs for Continuous Data, GLMs for Count Data, Generalized (Non-)Linear Models with Group-Specific Terms,  Regularized Linear Models, Hierarchical Partial Pooling for Repeated Binary Trials. We will cover these topics within the context of an applied Bayesian workflow that includes exploratory data analysis, model fitting, and model checking.<br>

<strong>Course Materials</strong>

Download textbook draft from <a href="https://vasishth.github.io/smlp2020/Bayes_CogSciDraft.pdf">here</a>.<br>

Videos: available <a href="https://vasishth.github.io/IntroductionBDA/index.html">here</a>.


<br><br>
<li><strong>Advanced Bayesian data analysis</strong> (maximum 30 participants). Taught by <a href="http://www.ling.uni-potsdam.de/~nicenboim/">Bruno Nicenboim</a> and <a href="https://vasishth.github.io/">Shravan Vasishth</a></li>

This course assumes that participants have some experience in Bayesian modeling already (using JAGS/WinBUGS/Stan, or some other probabilistic programming language) and want to learn more advanced methods. Participants should have worked through or be familiar with the material in the first four chapters of our book draft: <a href="https://vasishth.github.io/Bayes_CogSci/">Introduction to Bayesian Data Analysis for Cognitive Science</a>. 
We will cover hierarchical modeling, multinomial processing trees, measurement error models, meta-analysis, mixture models, and using Bayes factors and k-fold cross validation.
<br><br>

<li><strong>Foundational methods in frequentist statistics</strong> (maximum 30 participants). Taught by  <a href="https://danielschad.github.io/">Daniel Schad</a>, video recordings by <a href="https://vasishth.github.io">Shravan Vasishth</a>.</li>

Participants will be expected to have used linear mixed models before, to the level of the textbook by <a href="http://www.bodowinter.com/blog/book-release-statistics-for-linguists">Winter (2019, Statistics for Linguists)</a>, and want to acquire a deeper knowledge of frequentist foundations, and understand the linear mixed model more deeply. Participants are expected to have fit multiple regressions. We will cover model selection, contrast coding, and using simulations to compute power. We will work on (at least some of) the participants' own datasets. <i>This course is not appropriate for researchers new to R or to frequentist statistics</i>.<br>

<strong>Course Materials</strong>

Download textbook draft from <a href="https://vasishth.github.io/smlp2020/Freq_CogSciDraft.pdf">here</a>.<br>

Videos: available <a href="https://vasishth.github.io/IntroductionStatistics/index.html">here</a>.


<br><br>

<li><strong>Advanced methods in frequentist statistics with Julia</strong> (maximum 30 participants). Taught by <a href="https://phillipalday.com/">Phillip Alday</a>,
<a href="http://pages.stat.wisc.edu/~bates/">Douglas Bates</a>, and  <a href="https://www.uni-potsdam.de/en/trainingswissenschaft/staff/rkliegl.html">Reinhold Kliegl</a> </li>
</ul>

Applicants must have experience with linear mixed models and be interested in learning how to carry out such analyses with the <a href="https://github.com/JuliaStats/MixedModels.jl">Julia-based MixedModels package</a>) (i.e., the analogue of the R-based lme4 package). Julia MixedModels has some significant advantages. Some of them are: (a) new and more efficient computational implementation, (b) speed — needed for, e.g.,  complex designs and the computation of statistical power, 
(c) more flexibility for selection of parsimonious mixed models, and 
(d) more flexibility in taking into account autocorrelations or other dependencies — typical  EEG-, fMRI-based time series (under development).

We <strong>do not expect</strong> profound knowledge of Julia from participants; the necessary subset of knowledge will be taught on the first day of the course. We do expect a readiness to <a href="https://julialang.org/downloads/">install Julia</a> and the confidence that with some basic instruction participants will be able to adapt prepared Julia scripts for their own data or to adapt some of their own lmer()-commands to the equivalent MixedModels()-commands. The course will be taught in a hybrid IDE. There is already the option to execute R chunks from within Julia, meaning one needs Julia primarily for execution of MixedModels command as replacement of lmer(). There is also an option to call Julia MixedModels from within R and process the resulting object like an lme4-object. Thus, much of pre- and postprocessing (e.g., data simulation for complex experimental designs; visualization of partial-effect interactions or shrinkage effects) can and will be carried out in the RStudio / R environment.
<br><br>
</div>


<div>
<h3>Fees</h3>

As the course is being carried out virtually, there will be no fee.
<br><br>
</div>


<div>
<h3>Contact details</h3>

For any questions regarding this summer school that have not been addressed on this home page already, please contact <a href="https://vasishth.github.io/">Shravan Vasishth</a>.
<br><br>
</div>

<div>
<h3>Funding</h3>

This summer school is funded by the DFG and is part of the <a href="https://www.uni-potsdam.de/sfb1287/index.html">SFB 1287, “Variability in Language and Its Limits”</a>.
</div>

</div>
<hr/>


</section>

</body>
</html>
